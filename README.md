# ğŸ“„ Llama-3.3-70B Document RAG QA

### âš¡ High-Performance RAG-based PDF Question Answering using Groq + LangChain + Streamlit

An advanced **Retrieval Augmented Generation (RAG)** based PDF Question
Answering application powered by:

-   ğŸ§  **Llama-3.3-70B-Versatile (via Groq API)**
-   ğŸ”— **LangChain**
-   ğŸ“š **Chroma Vector Database**
-   ğŸ¤— **HuggingFace Embeddings**
-   ğŸŒ **Streamlit UI**

This app allows users to upload PDF documents and ask questions based on
their content using a blazing-fast LLM inference engine powered by
**Groq**.

------------------------------------------------------------------------

# ğŸš€ Features

-   ğŸ“¤ Upload one or multiple PDF files
-   ğŸ” Automatic document chunking & embedding
-   ğŸ—„ï¸ Vector storage using ChromaDB
-   âš¡ Lightning-fast inference with Groq
-   ğŸ¤– Llama-3.3-70B model integration
-   ğŸ’¬ Conversational question answering
-   ğŸ§  Context-aware RAG pipeline
-   ğŸŒ Streamlit Web Interface
-   â˜ï¸ Deployable on Streamlit Cloud

------------------------------------------------------------------------

# ğŸ—ï¸ Architecture

User Question\
â†“\
Retriever (Chroma)\
â†“\
Relevant Document Chunks\
â†“\
Llama-3.3-70B (Groq API)\
â†“\
Final Answer

------------------------------------------------------------------------

# ğŸ“¦ Tech Stack

  Component      Technology
  -------------- --------------------------------
  LLM            Llama-3.3-70B-Versatile (Groq)
  Framework      LangChain
  Embeddings     HuggingFace Transformers
  Vector Store   ChromaDB
  Backend        Python
  UI             Streamlit
  Deployment     Streamlit Cloud

------------------------------------------------------------------------

# ğŸ› ï¸ Installation (Local Setup)

## 1ï¸âƒ£ Clone Repository

``` bash
git clone https://github.com/your-username/pdfQAapp.git
cd pdfQAapp
```

## 2ï¸âƒ£ Create Virtual Environment (Python 3.10 Recommended)

``` bash
py -3.10 -m venv venv
venv\Scripts\activate
```

## 3ï¸âƒ£ Install Dependencies

``` bash
pip install -r requirements.txt
```

------------------------------------------------------------------------

# ğŸ”‘ Environment Variables

Create a `.env` file in root directory:

    GROQ_API_KEY=your_groq_api_key_here

------------------------------------------------------------------------

# ğŸŒ Run Application

``` bash
streamlit run app.py
```

Then open:\
http://localhost:8501

------------------------------------------------------------------------

# â˜ï¸ Deploy on Streamlit Cloud

1.  Push code to GitHub\
2.  Open Streamlit Cloud\
3.  Deploy new app\
4.  Add secret in **App Settings â†’ Secrets**

```{=html}
<!-- -->
```
    GROQ_API_KEY = "your_actual_key_here"

5.  Deploy ğŸš€

------------------------------------------------------------------------

# ğŸ§  Model Details

### ğŸ”¥ Llama-3.3-70B-Versatile

-   70 Billion parameters
-   Optimized for reasoning & instruction following
-   High-speed inference via Groq
-   Low latency RAG response generation

------------------------------------------------------------------------

# ğŸ“ Project Structure

    pdfQAapp/
    â”‚
    â”œâ”€â”€ app.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ .env
    â”œâ”€â”€ README.md
    â””â”€â”€ vectorstore/

------------------------------------------------------------------------

# âš ï¸ Important Notes

-   Use **Python 3.10 (64-bit)** for best compatibility
-   Do NOT use 32-bit Python
-   Keep your API keys secure
-   Never upload `.env` to GitHub
-   Use `.gitignore` to protect secrets

------------------------------------------------------------------------

# ğŸ‘©â€ğŸ’» Author

**Aishwarya Gupta**\
B.Tech CSE (AI Specialization)\
RAG \| GenAI \| LangChain \| LLM Applications

------------------------------------------------------------------------

# â­ If You Like This Project

Give it a â­ on GitHub\
Fork & Improve\
Use it in your AI portfolio

------------------------------------------------------------------------

# ğŸ Conclusion

This project demonstrates a production-ready:

âœ… Retrieval Augmented Generation system\
âœ… Groq LLM integration\
âœ… LangChain orchestration\
âœ… Real-time Streamlit deployment

A powerful addition to any AI/ML engineer's portfolio.
