# ğŸ“„ Llama-3.3-70B Document RAG QA

### âš¡ Fast PDF Question Answering using Groq + LangChain + Streamlit

A production-ready **Retrieval Augmented Generation (RAG)** application that allows users to upload a PDF and ask questions about its content using:

* ğŸ§  **Llama-3.3-70B-Versatile (Groq API)**
* ğŸ”— **LangChain**
* ğŸ—„ **Chroma Vector Store**
* ğŸ¤— **HuggingFace Embeddings**
* ğŸŒ **Streamlit UI**

This app is fully deployable on **Streamlit Cloud**.

---

# ğŸš€ Features

* ğŸ“¤ Upload a PDF document
* ğŸ” Automatic text chunking
* ğŸ§  Embedding generation using HuggingFace
* ğŸ—„ In-memory Chroma vector database
* âš¡ High-speed LLM inference via Groq
* ğŸ’¬ Context-aware Question Answering
* â˜ï¸ Cloud deployable
* ğŸ” Secure API key using Streamlit Secrets

---

# ğŸ—ï¸ Architecture

User Uploads PDF     
   â†“

PyPDFLoader
    
  â†“

Text Splitting
  
  â†“

HuggingFace Embeddings
  
  â†“

Chroma Vector Store
  
  â†“

Retriever
  
  â†“

Llama-3.3-70B (Groq)
  
  â†“

Final Answer

---

# ğŸ“¦ Tech Stack

| Component    | Technology                          |
| ------------ | ----------------------------------- |
| LLM          | Llama-3.3-70B-Versatile (Groq)      |
| Framework    | LangChain                           |
| Embeddings   | HuggingFace (sentence-transformers) |
| Vector Store | Chroma                              |
| UI           | Streamlit                           |
| PDF Loader   | PyPDF                               |
| Deployment   | Streamlit Cloud                     |

---

# ğŸ› ï¸ Local Setup

## 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/pdf-qa-app.git
cd pdf-qa-app
```

## 2ï¸âƒ£ Create Virtual Environment (Python 3.10 Recommended)

```bash
py -3.10 -m venv venv
venv\Scripts\activate
```

## 3ï¸âƒ£ Install Requirements

```bash
pip install -r requirements.txt
```

---

# ğŸ“„ requirements.txt

```txt
streamlit==1.33.0
langchain==0.1.20
langchain-core==0.1.53
langchain-community==0.0.38
langchain-text-splitters==0.0.2
langchain-huggingface==0.0.3
langchain-groq==0.1.3
chromadb==0.5.23
sentence-transformers==2.7.0
pypdf==4.2.0
```

---

# ğŸ”‘ API Key Setup

This app uses **Streamlit Secrets** instead of `.env`.

## Local Development

Create a file:

```
.streamlit/secrets.toml
```

Add:

```toml
GROQ_API_KEY = "your_actual_groq_api_key"
```

---

# â˜ï¸ Deploy on Streamlit Cloud

1. Push project to GitHub
2. Go to Streamlit Cloud
3. Deploy new app
4. Go to **App Settings â†’ Secrets**
5. Add:

```toml
GROQ_API_KEY = "your_actual_groq_api_key"
```

6. Deploy ğŸš€

---

# â–¶ï¸ Run Locally

```bash
streamlit run app.py
```

Open:

```
http://localhost:8501
```

---

# ğŸ“ Project Structure

```
pdf-qa-app/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .streamlit/
â”‚    â””â”€â”€ secrets.toml
â””â”€â”€ temp.pdf (generated automatically)
```

---

# âš ï¸ Important Notes

* âœ… Use **Python 3.10 (64-bit)**
* âŒ Do NOT use 32-bit Python
* ğŸ” Never commit secrets.toml
* ğŸ“Œ HuggingFace model loads once (cached)
* â˜ï¸ Fully Streamlit Cloud compatible

---

# ğŸ§  Model Info

### Llama-3.3-70B-Versatile

* 70B parameters
* Strong reasoning capabilities
* Low latency via Groq hardware acceleration
* Excellent for RAG pipelines

---

# ğŸ‘©â€ğŸ’» Author

**Aishwarya Gupta**
B.Tech CSE (AI Specialization)
GenAI | RAG | LangChain | LLM Applications

---

# â­ This project demonstrates:

âœ… Production RAG pipeline
âœ… Secure API management
âœ… Groq LLM integration
âœ… Vector database usage
âœ… Streamlit cloud deployment
